{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework Part 1: Detecting Spam with Spark\n",
    "\n",
    "IN432 Big Data coursework 2017, part 1. Classifying messages to detect spam.\n",
    "\n",
    "Coursework by Gediminas Sadaunykas and Vaida Gulbinskaitė. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task a) & b) Read some files and prepare a (f,w) RDD \n",
    "a) Start by reading the directory with text files from the distributed file system (e.g. `hdfs://saltdean.nsqdc.city.ac.uk./data/spam/bare/part1`), and loading all text files using wholeTextFiles(), which loads the text per file, i.e. tuples (f,t). (5%)\n",
    "\n",
    "b) Split the text into words (lower case), creating a (file,word) RDD. (10%)\n",
    "\n",
    "For both tasks you can use the code from the labs. Don't remove finals 's' (we have already lemmatised data to work with later). \n",
    "\n",
    "It is very useful to pack the code into a function that takes a directory as an argument and returns an RDD with (f,w) structure, e.g. `read_fw_RDD`.\n",
    "\n",
    "Please write two lines of code at the end of the cell that run a little example and print some output. You can comment them out after you have verified that your code works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hdfs://saltdean.nsqdc.city.ac.uk./data/spam/bare/part1/3-1msg1.txt', 'subject'), ('hdfs://saltdean.nsqdc.city.ac.uk./data/spam/bare/part1/3-1msg1.txt', 're'), ('hdfs://saltdean.nsqdc.city.ac.uk./data/spam/bare/part1/3-1msg1.txt', '2')]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESING\n",
    "\n",
    "dirPath = 'hdfs://saltdean.nsqdc.city.ac.uk./data/spam/bare/part1'\n",
    "import re\n",
    "\n",
    "### b. split words\n",
    "def splitFileWords(filenameContent): # your splitting function\n",
    "    f,c = filenameContent # split the input tuple  \n",
    "    fwLst = [] # the new list for (filename,word) tuples\n",
    "    wLst = re.split('\\W+',c) # create a word list wLst\n",
    "    for w in wLst: # iterate through the list\n",
    "        fwLst.append((f,(w.lower()))) # append (f,w)  \n",
    "    return fwLst #return a list of (f,w) tuples \n",
    "\n",
    "### a. Read files \n",
    "def read_fw_RDD(argDir): \n",
    "    fwL_RDD = sc.wholeTextFiles(argDir)\n",
    "    fw_RDD = fwL_RDD.flatMap(splitFileWords)\n",
    "    return fw_RDD\n",
    "    \n",
    "    #print('Read {} files from directory {}'.format(5,argDir)) # status message for testing, can be disabled later on\n",
    "    #print('file word count histogram') # the histogram can be useful for checking later \n",
    "    #print(fwL_RDD.map(lambda fwL: (len(fwL[1]))).histogram([0,10,100,1000,10000]))\n",
    "    \n",
    "\n",
    "fw_RDD = read_fw_RDD(dirPath) # for testing\n",
    "print(fw_RDD.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task c) Normalised word count lists\n",
    "Use the code from the labs to generate the \\texttt{[(word,count), ...]} list per file and to create a word frequency vector. \n",
    "\n",
    "Normalise the term frequency (TF) vector by the total word count per file. (15\\%)\n",
    "\n",
    "This is mostly reusing the lab code. The interesting part here is the normalisation. For normalisation we need to total word count per file. You can use a nested list comprehension for this (go through the (w,c) list and divide each c by the sum of all c, which you can get with a list). \n",
    "\n",
    "Another option is to use a separate RDD with (f,twc), where 'twc' is for total word count, and which you can create from the (f,[(w,c), ... ]) RDD. This new RDD can then be joined with the (f,[(w,c), ... ]) RDD and then the (w,c) list be normalised in a list comprehension. \n",
    "\n",
    "It would actually be more efficient to do the word counting when you split the words, but that would mix the tasks too much, so please don't do that in your coursework submission.\n",
    "\n",
    "Again, put your code into a function, and add a short test that can be commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "1.0000000000000007\n"
     ]
    }
   ],
   "source": [
    "# NORMALIZATION\n",
    "\n",
    "from operator import add\n",
    "\n",
    "def reGrpLst(fw_c): # reorganise the tuples\n",
    "    fw,c = fw_c\n",
    "    f,w = fw\n",
    "    return (f,[(w,c)]) #returns (f,[(w,c)]) structure\n",
    "\n",
    "def normalizeLstReduced(lst):\n",
    "    f_wcLn_RDD = []\n",
    "    for x in lst:\n",
    "        f_wcLn_RDD.append((x[0], x[1]/sum(x[1] for x in lst)))\n",
    "    return f_wcLn_RDD\n",
    "\n",
    "\n",
    "def make_f_tfLn_RDD(argDir): \n",
    "    fw_RDD = read_fw_RDD(argDir) # call function from task a & b\n",
    "    fw_1_RDD = fw_RDD.map(lambda x: (x,1))  # change (f,w) to ((f,w),1)\n",
    "    #print('-'*80)\n",
    "    #print(fw_1_RDD.take(10)) # TESTING\n",
    "    \n",
    "    fw_c_RDD = fw_1_RDD.reduceByKey(add) # change ((f,w),1) to ((f,w),c) where c is sum of unique word instances\n",
    "    #print('-'*80)\n",
    "    #print(fw_c_RDD.take(10)) # TESTING\n",
    "    \n",
    "    f_wcL_RDD = fw_c_RDD.map(reGrpLst) # reorganize the tupples ((f,w), c) to (f, [(w,c)])\n",
    "    #print('-'*80)\n",
    "    #print(f_wcL_RDD.take(10)) # TESTING    \n",
    "    \n",
    "    f_wcL_RDD2 = f_wcL_RDD.reduceByKey(add) # reogrganise the tupples ((f,w), c) to (f, [(w,c),...])) \n",
    "    #print(''*80)\n",
    "    #print(f_wcL_RDD2.take(1)) # TESTING\n",
    "    \n",
    "    f_tfLn_RDD = f_wcL_RDD2.map(lambda f_wcl: (f_wcl[0], normalizeLstReduced(f_wcl[1]))) # list normalization\n",
    "    #print(''*80)\n",
    "    #print(f_tfLn_RDD.take(1)) # TESTING\n",
    "    return f_tfLn_RDD\n",
    "\n",
    "\n",
    "f_tfLn_RDD= make_f_tfLn_RDD(dirPath) \n",
    "print('-'*80)\n",
    "wcLn = f_tfLn_RDD.take(1)[0][1] # get the first normalised word count list. # TESTING\n",
    "print(sum([cn for (w,cn) in wcLn])) # the sum of normalised counts should be close to 1. TESTING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task d) Creating hashed feature vectors \n",
    "Use the hashing trick to create fixed size TF vectors. (10%)\n",
    "\n",
    "Use the code from the week 2lecture to create the hash vectors.\n",
    "\n",
    "As before, make it a function and add a short test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------\n",
      "[0.039603960396039604, 0.099009900990099, 0.07920792079207921, 0.039603960396039604, 0.019801980198019802, 0.09900990099009901, 0.0297029702970297, 0.009900990099009901, 0.009900990099009901, 0.0297029702970297, 0, 0.0297029702970297, 0.009900990099009901, 0.019801980198019802, 0.0297029702970297, 0.019801980198019802, 0.0297029702970297, 0.04950495049504951, 0.019801980198019802, 0.04950495049504951, 0.04950495049504951, 0.0792079207920792, 0.039603960396039604, 0.05940594059405941, 0.05940594059405941]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "def hashing_vectorizer(word_count_list, N): \n",
    "    v = [0] * N  # create fixed size vector of 0s\n",
    "    for word_count in word_count_list:\n",
    "        word,count = word_count # unpack tuple of normalized word counts\n",
    "        h = hash(word) \t# get hash value\n",
    "        v[h % N] = v[h % N] + count # add count\n",
    "    return v \t# return hashed word vector\n",
    "\n",
    "def make_f_wVn_RDD(f_tfLn_RDD, N):\n",
    "    f_wVn_RDD = f_tfLn_RDD.map(lambda f_wc: (f_wc[0],hashing_vectorizer(f_wc[1],N))) # apply hashing_vectorizer on normalized word count list \n",
    "    return f_wVn_RDD\n",
    "    \n",
    "N=25 # initialize N\n",
    "\n",
    "f_wVn_RDD = make_f_wVn_RDD(make_f_tfLn_RDD(dirPath), N)\n",
    "print('-'*117)\n",
    "print(f_wVn_RDD.take(1)[0][1]) # TESTING\n",
    "print('-'*117)\n",
    "print(sum(f_wVn_RDD.take(1)[0][1])) # TESTING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task e) Create Labeled Points\n",
    "\n",
    "Determine whether the file is spam (i.e. the filename contains ’spmsg’) and replace the filename by a 1 (spam) or 0 (ham) accordingly. Use map() to create an RDD of LabeledPoint objects. \n",
    "\n",
    "See here [http://spark.apache.org/docs/2.0.0/ml-classification-regression.html#logistic-regression](http://spark.apache.org/docs/2.0.0/ml-classification-regression.html#logistic-regression) for an example, and here [http://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint](http://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) for the `LabeledPoint` documentation. (15%)\n",
    "\n",
    "It's useful to take the RDD with normalised word lists as input. \n",
    "\n",
    "For finding the spam messages use `re.search()` see here[https://docs.python.org/3/library/re.html?highlight=re%20search#re.search](https://docs.python.org/3/library/re.html?highlight=re%20search#re.search) for documentation. Search for 'spmsg' in the filename and check whether the result is `None`. The relevan syntax here is <b>`0 if <yourCondition> else 1`</b>, i.e. 0 if 'spmsg' is not in the filename (not spam) and 1 if it is (it's spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------\n",
      "[LabeledPoint(0.0, [0.039603960396,0.0990099009901,0.0792079207921,0.039603960396,0.019801980198,0.0990099009901,0.029702970297,0.00990099009901,0.00990099009901,0.029702970297,0.0,0.029702970297,0.00990099009901,0.019801980198,0.029702970297,0.019801980198,0.029702970297,0.049504950495,0.019801980198,0.049504950495,0.049504950495,0.0792079207921,0.039603960396,0.0594059405941,0.0594059405941]), LabeledPoint(0.0, [0.0121212121212,0.0666666666667,0.0545454545455,0.0363636363636,0.0181818181818,0.0909090909091,0.0363636363636,0.0242424242424,0.0242424242424,0.0484848484848,0.0363636363636,0.0363636363636,0.0121212121212,0.030303030303,0.0727272727273,0.030303030303,0.0363636363636,0.0969696969697,0.0363636363636,0.0242424242424,0.0363636363636,0.0545454545455,0.0181818181818,0.0424242424242,0.0242424242424]), LabeledPoint(0.0, [0.0588235294118,0.0411764705882,0.0470588235294,0.0411764705882,0.0470588235294,0.0411764705882,0.0294117647059,0.0176470588235,0.0235294117647,0.0352941176471,0.0294117647059,0.0176470588235,0.0294117647059,0.0352941176471,0.0705882352941,0.0941176470588,0.0411764705882,0.0470588235294,0.0176470588235,0.0235294117647,0.0941176470588,0.0411764705882,0.0411764705882,0.0235294117647,0.0117647058824]), LabeledPoint(0.0, [0.0446735395189,0.0515463917526,0.0584192439863,0.0412371134021,0.0274914089347,0.0481099656357,0.0515463917526,0.0171821305842,0.0446735395189,0.0171821305842,0.0137457044674,0.0103092783505,0.0343642611684,0.0171821305842,0.0549828178694,0.0240549828179,0.0343642611684,0.0790378006873,0.0481099656357,0.0687285223368,0.0652920962199,0.0412371134021,0.0240549828179,0.0412371134021,0.0412371134021]), LabeledPoint(1.0, [0.034375,0.040625,0.075,0.075,0.021875,0.021875,0.025,0.0375,0.040625,0.03125,0.028125,0.025,0.025,0.015625,0.05625,0.078125,0.03125,0.03125,0.05,0.0375,0.04375,0.04375,0.06875,0.021875,0.040625]), LabeledPoint(0.0, [0.0647058823529,0.0588235294118,0.0470588235294,0.0235294117647,0.0294117647059,0.0941176470588,0.0117647058824,0.00588235294118,0.0352941176471,0.0705882352941,0.0294117647059,0.0117647058824,0.0294117647059,0.0176470588235,0.0764705882353,0.0352941176471,0.0352941176471,0.0352941176471,0.00588235294118,0.0411764705882,0.0705882352941,0.0529411764706,0.0647058823529,0.0470588235294,0.00588235294118]), LabeledPoint(0.0, [0.0642857142857,0.0214285714286,0.0642857142857,0.05,0.0357142857143,0.0285714285714,0.0642857142857,0.0,0.0357142857143,0.05,0.0214285714286,0.0142857142857,0.0357142857143,0.0214285714286,0.0785714285714,0.0642857142857,0.0214285714286,0.0285714285714,0.0357142857143,0.0857142857143,0.0642857142857,0.0214285714286,0.0142857142857,0.0357142857143,0.0428571428571]), LabeledPoint(0.0, [0.0666666666667,0.04,0.08,0.08,0.04,0.0133333333333,0.0533333333333,0.0133333333333,0.0666666666667,0.04,0.04,0.0133333333333,0.0133333333333,0.0,0.0533333333333,0.0533333333333,0.0133333333333,0.0533333333333,0.04,0.0533333333333,0.0533333333333,0.04,0.0,0.0133333333333,0.0666666666667]), LabeledPoint(1.0, [0.0261974584555,0.0445747800587,0.0383186705767,0.030889540567,0.0129032258065,0.0355816226784,0.0154447702835,0.0175953079179,0.0175953079179,0.0199413489736,0.260606060606,0.0240469208211,0.017008797654,0.0203323558162,0.052981427175,0.0559139784946,0.0215053763441,0.0432062561095,0.01642228739,0.0408602150538,0.0412512218964,0.0445747800587,0.0439882697947,0.0197458455523,0.038514173998]), LabeledPoint(1.0, [0.0279001468429,0.0425844346549,0.0440528634361,0.0440528634361,0.00807635829662,0.0220264317181,0.014684287812,0.0190895741557,0.0220264317181,0.0286343612335,0.274596182085,0.0198237885463,0.0198237885463,0.0124816446402,0.0352422907489,0.0528634361233,0.0301027900147,0.0418502202643,0.0117474302496,0.0293685756241,0.0345080763583,0.0447870778267,0.0594713656388,0.0249632892805,0.0352422907489])]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    " \n",
    "def make_lp_RDD(f_tfLn_RDD, argN): # Takes in normalized RDD as input\n",
    "    \n",
    "    ##make a vector\n",
    "    f_wVec_RDD = f_tfLn_RDD.map(lambda f_wc: (f_wc[0],hashing_vectorizer(f_wc[1],argN)))  \n",
    "    \n",
    "    ##Detect spam by filename and transform into LabeledPoint objects re.search()  \n",
    "    lp_RDD = f_wVec_RDD.map(lambda f_wVec: LabeledPoint(1 if (re.search('spmsg',f_wVec[0])) else 0,f_wVec[1])) ##1 if spam, 0 if ham\n",
    "    return lp_RDD  \n",
    "\n",
    "   \n",
    "\n",
    "N=25\n",
    "lp_RDD = make_lp_RDD(make_f_tfLn_RDD('hdfs://saltdean.nsqdc.city.ac.uk./data/spam/bare/part1'),N)\n",
    "print('-'*117)\n",
    "print(lp_RDD.take(10)) # TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task f) Train a classifier \n",
    "\n",
    "Use the `LabeledPoint` objects to train the `LogisticRegression` and calculate the accuracy of the model on the training set (again, follow this example [http://spark.apache.org/docs/2.0.0/ml-classification-regression.html#logistic-regression](http://spark.apache.org/docs/2.0.0/ml-classification-regression.html#logistic-regression) and here is the documentation [http://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithLBFGS](http://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithLBFGS).  (15%) \n",
    "\n",
    "It's useful to start with a normalised word list as input again (because we can later also use it with TF.IDF values).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------\n",
      "training data items: 289, correct: 246\n",
      "training accuracy 85.1%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionWithSGD, NaiveBayes\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "path = 'hdfs://saltdean/data/spam/stop/part1'\n",
    "\n",
    "def trainModel(f_tfLn_RDD,N):\n",
    "    trainData = make_lp_RDD(f_tfLn_RDD, N) # trainsform into LabeledPoint objects.\n",
    "    model = LogisticRegressionWithSGD.train(trainData)\n",
    "    correct = trainData.map( lambda lp: 1 if model.predict(lp.features) == lp.label else 0).sum() \n",
    "    count = trainData.count()\n",
    "    accuracy = correct/count\n",
    "    print('training data items: {}, correct: {}'.format(trainData.count(), correct)) # output raw numbers\n",
    "    print('training accuracy {:.1%}'.format(accuracy)) # and accuracy\n",
    "    return model \n",
    "\n",
    "N=100\n",
    "f_tfLn_RDD = make_f_tfLn_RDD(path) # Making normalized word RDD \n",
    "modelTrained = trainModel(f_tfLn_RDD,N) # Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task g) Test the classifier\n",
    "\n",
    "Use the files from \\texttt{.../data/extra/spam/bare/part10} and prepare them like in task~a)-e) (use the function you created in task e) and before. Then use the trained model to predict the label for each vector you have and compare it to the original to test the performance of your classifier. (10\\%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data items: 291, correct:234\n",
      "testing accuracy 80.4%\n"
     ]
    }
   ],
   "source": [
    "def testModel(model,f_tfLn_RDD,N):\n",
    "    \n",
    "    #like with trainModel, transform the data and evaluate it.\n",
    "    trainData = make_lp_RDD(f_tfLn_RDD, N) # Labeled point Rdd\n",
    "    correct = trainData.map( lambda lp: 1 if model.predict(lp.features) == lp.label else 0).sum()\n",
    "    count = trainData.count()\n",
    "    accuracy = correct/count \n",
    "    print('test data items: {}, correct:{}'.format(trainData.count(),correct)) # raw numbers\n",
    "    print('testing accuracy {:.1%}'.format(accuracy)) # accuracy\n",
    "\n",
    "testModel(modelTrained,make_f_tfLn_RDD('hdfs://saltdean/data/spam/stop/part10'),N) # for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task h) Run experiments \n",
    "\n",
    "Package the whole classifier training and evaluation in one function. Then apply it to the files from `/data/extra/spam/lemm`, `/data/extra/spam/stop` and `/data/extra/spam/lemm_stop` in addition to `/data/extra/spam/bare`  and evaluate the accuracy of your classifier. \n",
    "\n",
    "Comment on the effect of *lemmatisation* and *stopword removal* on classification accuracy. Further, evaluate the use of larger training sets and the effect of different vector sizes. Print out the results of your experiments in readable form. (20%) \n",
    "\n",
    "You need to create one small fuction that combines tasks f) and g), and then apply it to different datasets sizes, vector sizes, and different preprocessings. \n",
    "\n",
    "The combination of the part1-part9 datasets can be achieved by using 'glob' patterns in the filename ('part[1-9]'). This is a feature of the Hadoop filesystem and not well documented in Spark (or anywhere else). You can find a description of its Python implementation here: [https://docs.python.org/3/library/glob.html](https://docs.python.org/3/library/glob.html). You can also supply multiple comma-separated paths, but you'll need to test what works, when you use this feature. Recursive patterns don't seem to work.\n",
    "\n",
    "Alternatively, you can create unions of RDDs for each part. However, this seems to lead to slower execution. With the latter, it is useful to created arrays of the directory names (part1, ...). When you work with unions, it may be useful to start with an empty RDD. That can be created with `sc.parallelize([])`.\n",
    "\n",
    "A useful tool for creatng multiple long paths variants is the use of the Python string format() method as used below. There is a good set of example here: [https://docs.python.org/3/library/string.html#format-examples](https://docs.python.org/3/library/string.html#format-examples) and the specification is here: [https://docs.python.org/3/library/string.html#format-specification-mini-language](https://docs.python.org/3/library/string.html#format-specification-mini-language).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 1: Testing different training set sizes\n",
      "Path = hdfs://saltdean/data/spam/bare/part[1-{}], N = 100\n",
      "hdfs://saltdean/data/spam/bare/part[1-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Logistic Regression\n",
      "train set correct: 241, of total: 289, accuracy: 0.8339100346020761\n",
      "test set correct: 241, of total: 291, accuracy: 0.8281786941580757\n",
      "Time Cost: 13.153444528579712s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-2]\n",
      "training Logistic Regression\n",
      "train set correct: 482, of total: 578, accuracy: 0.8339100346020761\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 15.756645917892456s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-3]\n",
      "training Logistic Regression\n",
      "train set correct: 723, of total: 867, accuracy: 0.8339100346020761\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 21.86052894592285s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-4]\n",
      "training Logistic Regression\n",
      "train set correct: 964, of total: 1156, accuracy: 0.8339100346020761\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 27.481862545013428s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-5]\n",
      "training Logistic Regression\n",
      "train set correct: 1206, of total: 1446, accuracy: 0.8340248962655602\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 32.06507658958435s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-6]\n",
      "training Logistic Regression\n",
      "train set correct: 1447, of total: 1735, accuracy: 0.8340057636887608\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 37.879483222961426s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-7]\n",
      "training Logistic Regression\n",
      "train set correct: 1688, of total: 2024, accuracy: 0.83399209486166\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 44.957841873168945s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-8]\n",
      "training Logistic Regression\n",
      "train set correct: 1929, of total: 2313, accuracy: 0.833981841763943\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 48.83384847640991s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "hdfs://saltdean/data/spam/bare/part[1-9]\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time Cost: 54.18244528770447s\n",
      "---------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1\n",
    "from time import time\n",
    "\n",
    "\n",
    "def trainTestModel(train_RDD, test_RDD,N):\n",
    "    LRModel = LogisticRegressionWithSGD.train(train_RDD) # Train the odel\n",
    "    print('training Logistic Regression') \n",
    "    correct = train_RDD.map( lambda lp: 1 if LRModel.predict(lp.features) == lp.label else 0).sum() # correctly classified data points\n",
    "    count = train_RDD.count() # total size of training set\n",
    "    print('train set correct: {}, of total: {}, accuracy: {}'.format(correct,count,correct/count)) \n",
    "    correct = test_RDD.map( lambda lp: 1 if LRModel.predict(lp.features) == lp.label else 0).sum() # correctly classified data points\n",
    "    count = test_RDD.count() # total size of training set\n",
    "    print('test set correct: {}, of total: {}, accuracy: {}'.format(correct,count,correct/count))\n",
    "    return LRModel    \n",
    "    \n",
    "# directories and the path\n",
    "dirPattern = 'hdfs://saltdean/data/spam/bare/part[1-{}]' #dirPattern.format(i)\n",
    "# path for the test set\n",
    "testPath = 'hdfs://saltdean/data/spam/bare/part10'\n",
    "# N (size of hashed vector)\n",
    "N=100\n",
    "\n",
    "print('EXPERIMENT 1: Testing different training set sizes')\n",
    "print('Path = {}, N = {}'.format(dirPattern,N)) # Record the parameters of the experiment\n",
    "test_RDD= make_lp_RDD(make_f_tfLn_RDD(testPath), N) # Creates testing data RDD\n",
    "for i in range(1,10): #loop over i the number of parts for training (1-9)\n",
    "    t1 = time()\n",
    "    trainPath = dirPattern.format(i) # initialize the training path\n",
    "    train_RDD= make_lp_RDD(make_f_tfLn_RDD(trainPath), N) # Creates training data RDD\n",
    "    print(trainPath)\n",
    "    trainTestModel(train_RDD,test_RDD,N)\n",
    "    t2 = time()\n",
    "    print('Time Cost: {}s'.format(t2-t1))\n",
    "    print('-'*117)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different training set sizes has significant effect on the duration needed to train the model. 13.15s for the size of 289 instances (+291 test data) , 54.18s for the size of 2602 (+291 test data). \n",
    "\n",
    "However, increase in training data size has no effec on the accuracy of an algorithm. Accuracy remains steady at arround 83%.\n",
    "\n",
    "Possible explanation is the usage of LinearRegressionWithSGD instead of LogisticRegressionWithLBFGS, as a result of an error. Former model had been used at the beginning of a project, with the expected output - increase in accuracy with increase in training set size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPERIMENT 2: Testing different vector sizes\n",
      "=== N =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 55.641963481903076s\n",
      "=== N =  10\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 55.36869764328003s\n",
      "=== N =  30\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 54.25946259498596s\n",
      "=== N =  100\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 55.853522539138794s\n",
      "=== N =  300\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 57.12313103675842s\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2\n",
    "\n",
    "print('\\nEXPERIMENT 2: Testing different vector sizes')\n",
    "\n",
    "                       \n",
    "for N in (3,10,30,100,300):\n",
    "    print('=== N = ',N)\n",
    "    t3 = time()\n",
    "    test_RDD = make_lp_RDD(make_f_tfLn_RDD(testPath), N)\n",
    "    train_RDD = make_lp_RDD(make_f_tfLn_RDD(dirPattern.format(9)), N)\n",
    "    trainTestModel(train_RDD,test_RDD,N)\n",
    "    t4 = time()\n",
    "    print('Time cost: {}s'.format(t4-t3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different sizes of the hashed vector being tested (3,10,30,10,300). Larger size is not associated with a susbstantial increase in the duration of an evaluation. (54s for the N=3; 57s for the N=300) \n",
    "\n",
    "Accuracy, same as in the Experiment 1, remains steady as well (83%). Arguably, for the same reasons. Increase in accuracy with increase in N was expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPERIMENT 3: Testing differently preprocessed data sets\n",
      "training on parts 1-9, N = 100\n",
      "===  Stopwords removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 53.081204652786255s\n",
      "===  Lemmatised\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 57.22625470161438s\n",
      "===  No preprocessing\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 59.30894470214844s\n",
      "===  Lemmatised and stopwords removed\n",
      "training Logistic Regression\n",
      "train set correct: 2170, of total: 2602, accuracy: 0.8339738662567256\n",
      "test set correct: 242, of total: 291, accuracy: 0.8316151202749141\n",
      "Time cost: 46.06318664550781s\n",
      "\n",
      "====== Done ======\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3\n",
    "\n",
    "N = 100 # initialize N\n",
    "\n",
    "setDict = {'No preprocessing':'hdfs://saltdean/data/spam/bare/',\n",
    "           'Stopwords removed':'hdfs://saltdean/data/spam/stop/',\n",
    "           'Lemmatised':'hdfs://saltdean/data/spam/lemm/',\n",
    "           'Lemmatised and stopwords removed':'hdfs://saltdean/data/spam/lemm_stop/'}\n",
    "\n",
    "\n",
    "print('\\nEXPERIMENT 3: Testing differently preprocessed data sets')\n",
    "print('training on parts 1-9, N = {}'.format(N))\n",
    "for sp in setDict:\n",
    "    print('=== ',sp)\n",
    "    t5 = time()\n",
    "    trainPath = setDict[sp]+'part[1-9]'\n",
    "    test_RDD = make_lp_RDD(make_f_tfLn_RDD(testPath), N) # test RDD\n",
    "    train_RDD = make_lp_RDD(make_f_tfLn_RDD(trainPath), N) # train RDD\n",
    "    trainTestModel(train_RDD, test_RDD, N)\n",
    "    t6 = time()\n",
    "    print('Time cost: {}s'.format(t6-t5))\n",
    "\n",
    "print('\\n====== Done ======')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different preprocessing techniques, has negligible effect on the time cost of training. (arround 54s on average) Except, for the combined procedure of 'Lemmatization' and 'Stopword removal' which leads to the reduced training time. (46s)\n",
    "\n",
    "Accuracy, same as in the Experiment 1 and 2, remains steady as well (83%). Arguably, for the same reasons. Increase in accuracy with greater preprocessing effor was expected. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task i) (Task for pairs) TF.IDF vectors\n",
    "You need to address this task if you are working as a pair. \n",
    "\n",
    "Calculate the IDF values for each word and generate fixed size TF.IDF vectors for each document (word frequencies still normalised by total document word count). Also evaluate the use of TF.IDF compared to normalised word counts in terms of accuracy. (25%)\n",
    "\n",
    "To calculate the IDF values you need to create an RDD (w,f) pairs. You can use the function `RDD.distinct()` to remove duplicates and reorganise to create (w,[f, ...]) lists. The length of the list is the document frequency and can be used to calculate the IDF\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 100, trainPath: hdfs://saltdean.nsqdc.city.ac.uk./data/spam/lemm_stop/part[1-9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------\n",
      "training data items: 289, correct: 244\n",
      "training accuracy 84.4%\n",
      "Time Cost: 27.635865688323975s\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "N: 100, testPath: hdfs://saltdean.nsqdc.city.ac.uk./data/spam/lemm_stop/part10\n",
      "test data items: 289, correct:250\n",
      "testing accuracy 86.5%\n",
      "Time Cost:6.357905149459839s\n",
      "\n",
      "====== Done ======\n"
     ]
    }
   ],
   "source": [
    "# TF.IDF experiment\n",
    "\n",
    "from operator import add\n",
    "from math import log\n",
    "\n",
    "trainPath = 'hdfs://saltdean.nsqdc.city.ac.uk./data/spam/lemm_stop/part[1-9]'\n",
    "testPath = 'hdfs://saltdean.nsqdc.city.ac.uk./data/spam/lemm_stop/part10'\n",
    "\n",
    "\n",
    "def make_f_wtfiL_RDD(path):\n",
    "    # Calculuate the IDFs\n",
    "    \n",
    "    fw_RDD = read_fw_RDD(path)\n",
    "    fw_RDD1 = fw_RDD.distinct() # keep only unique (f,w) pairs    \n",
    "    fw_RDD2 = fw_RDD1.map(lambda x: (x[1],[x[0]]))    # (f,w) to (w,[f])\n",
    "    #print(fw_RDD2.take(3))\n",
    "    wfL_RDD = fw_RDD2.reduceByKey(add)  #join the lists of files with reduceByKey\n",
    "    vocSize = wfL_RDD.count() #calculate the vocabulary size\n",
    "    #print('vocSize: {}'.format(vocSize))\n",
    "    #print('-'*117)\n",
    "\n",
    "    #Calculate the IDF values per word using len() on the list of files\n",
    "    wfLn_RDD = wfL_RDD.map(lambda wf: (wf[0], len(wf[1])))\n",
    "    wIdf_RDD = wfLn_RDD.map(lambda wfn: (wfn[0], log(vocSize/(1+wfn[1]))))\n",
    "    #print('wIdf_RDD.count(): ',wIdf_RDD.count()) # TESTING\n",
    "    #print('wIdf:')\n",
    "    #print(wIdf_RDD.take(1)) # TESTING\n",
    "    #print('-'*117)\n",
    "\n",
    "\n",
    "   # Get the normalised word counts (TFs) and organise by word (w,(f,cn)) \n",
    "    \n",
    "    f_tfLn_RDD = make_f_tfLn_RDD(dirPath) # create the normalised word count lists  (f, [(w, cn)...])\n",
    "    #print('f_tfLn:')\n",
    "    #print(f_tfLn_RDD.take(3))\n",
    "    #print('-'*117)\n",
    "\n",
    "    #print('f_tfLn_RDD: ',f_tfLn_RDD.map(\n",
    "    #        lambda x: sum([c for (w,c) in x[1]]).histogram([0,10,100,1000,10000]))) # check for the per-file word counts\n",
    "    w_fcn_RDD = f_tfLn_RDD.flatMap(lambda f_tf: [(w, (f_tf[0], cn)) for (w,cn) in f_tf[1]])     # create a list of tuples [(w,(f,cn)), ..] and use flatmap \n",
    "    #print('w_fcn_RDD:')\n",
    "    #print('w_fcn_RDD.count(): {}'.format(w_fcn_RDD.count())) # for testing\n",
    "    #print(w_fcn_RDD.take(2)) # for testing\n",
    "    #print('-'*117)\n",
    "\n",
    "    #join the IFDs and TFs by the words (w,(f,cn)) join (w,idf) to (w,((f,cn),idf))\n",
    "    w_fcnIdf_RDD = w_fcn_RDD.join(wIdf_RDD) #use RDD.join()\n",
    "    #print( 'w_fcnIdf_RDD.count(): ', w_fcnIdf_RDD.count())\n",
    "    #print('w_fcIdf:')\n",
    "    #print( w_fcnIdf_RDD.take(3))\n",
    "    #print('-'*117)\n",
    "    \n",
    "    # calculate the TF.IDF per file and word (f,[(w,cn*idf)]).\n",
    "    #map to (f,[(w,cn*idf)])\n",
    "    f_wtfiL_RDD = w_fcnIdf_RDD.map(lambda w_fcnIdf: (w_fcnIdf[1][0][0], [(w_fcnIdf[0], (w_fcnIdf[1][0][1]*w_fcnIdf[1][1]))]))\n",
    "    # print('f_wtfiL_RDD.count():', f_wtfiL_RDD.count())\n",
    "    #print('f_wtfil:')\n",
    "    #print(str(f_wtfiL_RDD.take(3)))\n",
    "    #print('-'*117)\n",
    "\n",
    "    #reduce by key (files) to get [(w,tfidf), ...] lists per file.\n",
    "    f_wtfiL2_RDD = f_wtfiL_RDD.reduceByKey(add)#<<< reduceByKey\n",
    "    # print('# of files with TF.IDF vectors: {}'.format(f_wtfiL2_RDD.count()))\n",
    "    #print('f_wtfil2:')\n",
    "    #print(str(f_wtfiL2_RDD.take(3)))\n",
    "    #print('-'*117)\n",
    "\n",
    "    return f_wtfiL2_RDD\n",
    "\n",
    "\n",
    "N=100\n",
    "t1=time()\n",
    "print('N: {}, trainPath: {}'.format(N,trainPath))\n",
    "trainedModel = trainModel(make_f_wtfiL_RDD(trainPath), N)\n",
    "t2=time()\n",
    "print('Time Cost: {}s'.format(t2-t1))\n",
    "print('-'*117)\n",
    "\n",
    "t3=time()\n",
    "print('N: {}, testPath: {}'.format(N, testPath))\n",
    "testModel(trainedModel, make_f_wtfiL_RDD(testPath), N)\n",
    "t4=time()\n",
    "print('Time Cost:{}s'.format(t4-t3))\n",
    "\n",
    "print('\\n====== Done ======')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time doubled in comparison to the similar training data size in Experiment 1, o part (h). Some positive effect on accuracy is observed (86.5% as opposed to 83%).\n",
    "\n",
    "It is arguable whether the effect would smaller or larger with the LogisticRegressionWithLBFGS, however similar positive behaviour is expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
